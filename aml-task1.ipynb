{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyod\n!pip install dataheroes\n\n# !pip install preprocess","metadata":{"execution":{"iopub.status.busy":"2023-10-28T18:07:08.754860Z","iopub.execute_input":"2023-10-28T18:07:08.755420Z","iopub.status.idle":"2023-10-28T18:07:49.281200Z","shell.execute_reply.started":"2023-10-28T18:07:08.755367Z","shell.execute_reply":"2023-10-28T18:07:49.279731Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting pyod\n  Downloading pyod-1.1.1.tar.gz (159 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.4/159.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from pyod) (1.3.2)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from pyod) (3.7.2)\nRequirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.10/site-packages (from pyod) (1.23.5)\nRequirement already satisfied: numba>=0.51 in /opt/conda/lib/python3.10/site-packages (from pyod) (0.57.1)\nRequirement already satisfied: scipy>=1.5.1 in /opt/conda/lib/python3.10/site-packages (from pyod) (1.11.2)\nRequirement already satisfied: scikit_learn>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from pyod) (1.2.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from pyod) (1.16.0)\nRequirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51->pyod) (0.40.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit_learn>=0.22.0->pyod) (3.1.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyod) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyod) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyod) (4.40.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyod) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyod) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyod) (9.5.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyod) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->pyod) (2.8.2)\nBuilding wheels for collected packages: pyod\n  Building wheel for pyod (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyod: filename=pyod-1.1.1-py3-none-any.whl size=190078 sha256=af1b8ea91cdaee04ba39fe8eff3e33930afbe2f9bc90fdcee6ed92058b5cfda4\n  Stored in directory: /root/.cache/pip/wheels/a3/42/d7/48a53ffc1466bd63932f28583c64ebf442114db14a0bfa8c95\nSuccessfully built pyod\nInstalling collected packages: pyod\nSuccessfully installed pyod-1.1.1\nCollecting dataheroes\n  Downloading dataheroes-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from dataheroes) (1.23.5)\nRequirement already satisfied: scipy>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from dataheroes) (1.11.2)\nRequirement already satisfied: scikit-learn>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from dataheroes) (1.2.2)\nRequirement already satisfied: pandas>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from dataheroes) (2.0.3)\nRequirement already satisfied: joblib>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from dataheroes) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from dataheroes) (3.1.0)\nRequirement already satisfied: networkx>=2.5 in /opt/conda/lib/python3.10/site-packages (from dataheroes) (3.1)\nRequirement already satisfied: pydot>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from dataheroes) (1.4.2)\nRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from dataheroes) (3.7.2)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from dataheroes) (5.9.3)\nRequirement already satisfied: tables>=3.6.1 in /opt/conda/lib/python3.10/site-packages (from dataheroes) (3.8.0)\nRequirement already satisfied: decorator>=5.1.1 in /opt/conda/lib/python3.10/site-packages (from dataheroes) (5.1.1)\nRequirement already satisfied: opentelemetry-sdk>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from dataheroes) (1.18.0)\nRequirement already satisfied: opentelemetry-api>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from dataheroes) (1.18.0)\nRequirement already satisfied: opentelemetry-exporter-otlp>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from dataheroes) (1.18.0)\nCollecting licensing>=0.31 (from dataheroes)\n  Downloading licensing-0.41.tar.gz (11 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->dataheroes) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->dataheroes) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->dataheroes) (4.40.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->dataheroes) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->dataheroes) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->dataheroes) (9.5.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->dataheroes) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->dataheroes) (2.8.2)\nRequirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.14.0->dataheroes) (1.2.14)\nCollecting importlib-metadata~=6.0.0 (from opentelemetry-api>=1.14.0->dataheroes)\n  Downloading importlib_metadata-6.0.1-py3-none-any.whl (21 kB)\nRequirement already satisfied: setuptools>=16.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.14.0->dataheroes) (68.0.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.18.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp>=1.14.0->dataheroes) (1.18.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.18.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp>=1.14.0->dataheroes) (1.18.0)\nRequirement already satisfied: backoff<3.0.0,>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.18.0->opentelemetry-exporter-otlp>=1.14.0->dataheroes) (2.2.1)\nRequirement already satisfied: googleapis-common-protos~=1.52 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.18.0->opentelemetry-exporter-otlp>=1.14.0->dataheroes) (1.59.1)\nRequirement already satisfied: grpcio<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.18.0->opentelemetry-exporter-otlp>=1.14.0->dataheroes) (1.51.3)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.18.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.18.0->opentelemetry-exporter-otlp>=1.14.0->dataheroes) (1.18.0)\nRequirement already satisfied: opentelemetry-proto==1.18.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.18.0->opentelemetry-exporter-otlp>=1.14.0->dataheroes) (1.18.0)\nRequirement already satisfied: requests~=2.7 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http==1.18.0->opentelemetry-exporter-otlp>=1.14.0->dataheroes) (2.31.0)\nRequirement already satisfied: protobuf<5.0,>=3.19 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-proto==1.18.0->opentelemetry-exporter-otlp-proto-grpc==1.18.0->opentelemetry-exporter-otlp>=1.14.0->dataheroes) (3.20.3)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.39b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-sdk>=1.14.0->dataheroes) (0.39b0)\nRequirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-sdk>=1.14.0->dataheroes) (4.6.3)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->dataheroes) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->dataheroes) (2023.3)\nRequirement already satisfied: cython>=0.29.21 in /opt/conda/lib/python3.10/site-packages (from tables>=3.6.1->dataheroes) (0.29.35)\nRequirement already satisfied: numexpr>=2.6.2 in /opt/conda/lib/python3.10/site-packages (from tables>=3.6.1->dataheroes) (2.8.5)\nRequirement already satisfied: blosc2~=2.0.0 in /opt/conda/lib/python3.10/site-packages (from tables>=3.6.1->dataheroes) (2.0.0)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from tables>=3.6.1->dataheroes) (9.0.0)\nRequirement already satisfied: msgpack in /opt/conda/lib/python3.10/site-packages (from blosc2~=2.0.0->tables>=3.6.1->dataheroes) (1.0.5)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.14.0->dataheroes) (1.14.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata~=6.0.0->opentelemetry-api>=1.14.0->dataheroes) (3.15.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->dataheroes) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.18.0->opentelemetry-exporter-otlp>=1.14.0->dataheroes) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.18.0->opentelemetry-exporter-otlp>=1.14.0->dataheroes) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.18.0->opentelemetry-exporter-otlp>=1.14.0->dataheroes) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.18.0->opentelemetry-exporter-otlp>=1.14.0->dataheroes) (2023.7.22)\nBuilding wheels for collected packages: licensing\n  Building wheel for licensing (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for licensing: filename=licensing-0.41-py3-none-any.whl size=13052 sha256=34c48081eb2a71fcb8d81f9868d01eb903408b287019b555032fbd83f223c6e8\n  Stored in directory: /root/.cache/pip/wheels/f4/48/bb/b1b19bd137eab8995aa23393709fc223e9418ab21bba0836b1\nSuccessfully built licensing\nInstalling collected packages: licensing, importlib-metadata, dataheroes\n  Attempting uninstall: importlib-metadata\n    Found existing installation: importlib-metadata 6.7.0\n    Uninstalling importlib-metadata-6.7.0:\n      Successfully uninstalled importlib-metadata-6.7.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncmudict 1.0.13 requires importlib-metadata<6.0.0,>=5.1.0, but you have importlib-metadata 6.0.1 which is incompatible.\nyapf 0.40.1 requires importlib-metadata>=6.6.0, but you have importlib-metadata 6.0.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed dataheroes-0.7.0 importlib-metadata-6.0.1 licensing-0.41\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport umap\nfrom mlxtend.plotting.pca_correlation_graph import corr2_coeff\nfrom pyod.models.ecod import ECOD\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import BayesianRidge\nfrom sklearn.preprocessing import RobustScaler, MinMaxScaler\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.feature_selection import f_regression, SelectKBest, chi2, VarianceThreshold\nimport numpy as np\nfrom sklearn.ensemble import ExtraTreesRegressor, AdaBoostRegressor, StackingRegressor, RandomForestRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.linear_model import RidgeCV, Lasso, ElasticNet, LinearRegression\nfrom sklearn.model_selection import KFold\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.impute import KNNImputer\nfrom sklearn.svm import LinearSVR, SVR\nfrom xgboost import XGBRegressor\n# from preprocess import preprocess\nfrom sklearn.metrics import r2_score\nfrom dataheroes import CoresetTreeServiceDTC\n","metadata":{"execution":{"iopub.status.busy":"2023-10-28T18:07:49.284593Z","iopub.execute_input":"2023-10-28T18:07:49.284998Z","iopub.status.idle":"2023-10-28T18:07:50.901586Z","shell.execute_reply.started":"2023-10-28T18:07:49.284949Z","shell.execute_reply":"2023-10-28T18:07:50.900216Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"##################### PRE-PROCESSSS ##################\n\n\ndef preprocess(X_train: np.array, y_train: np.array, X_test: np.array):\n    X_train, X_test = impute_mv(X_train, X_test)\n    print(\"Done with imputation\")\n    X_train, X_test = scale_data(X_train, X_test)\n    print(\"Done with Scaling\")\n\n    # TODO\n    X_train, X_test = detect_remove_outliers(X_train,y_train, X_test)\n    print(\"Done with outliers\")\n\n    X_train, X_test = select_features(X_train, y_train, X_test)\n    print(\"Done with Feature selection\")\n\n#     X_train, X_test = reduce_dim(X_train, X_test)\n#     print(\"Done with reducing dim\")\n\n    return X_train, y_train, X_test\n\n\ndef reduce_dim(X_train, X_test, method: str = 'PCA'):\n    if method == 'PCA':\n        reducer = PCA(n_components='mle', svd_solver='auto')\n\n    elif method == 'UMAP':\n        reducer = umap.UMAP()\n\n    else:\n        return X_train, X_test\n\n    X_train = reducer.fit_transform(X_train)\n    X_test = reducer.transform(X_test)\n    return X_train, X_test\n\n\ndef select_features(X_train: np.array, y_train: np.array, X_test: np.array):\n    X_train, X_test = remove_correlated(X_train, X_test)\n\n    # # Chi\n    # f_p_values = chi2(X_train, y_train)\n    # print(f_p_values)\n\n    # Select k best\n    fs = SelectKBest(score_func=f_regression, k=175)\n\n    X_train = fs.fit_transform(X_train, y_train.ravel())\n    X_test = fs.transform(X_test)\n    return X_train, X_test\n\n\ndef remove_correlated(X_train: np.array, X_test: np.array):\n    # Constant features\n    var_threshold = VarianceThreshold(threshold=0)  # threshold = 0 for constant\n    var_threshold.fit_transform(X_train)\n    var_threshold.transform(X_test)\n\n    # Correlated\n    cor = corr2_coeff(X_train.T, X_train.T)\n    p = np.argwhere(np.triu(np.isclose(cor, 1), 1))\n    X_train = np.delete(X_train, p[:, 1], axis=1)\n    X_test = np.delete(X_test, p[:, 1], axis=1)\n    return X_train, X_test\n\n\ndef scale_data(X_train: np.array, X_test: np.array, method: str = 'min_max'):\n    if method == 'robust':\n        transformer = RobustScaler()\n    elif method == 'min_max':\n        transformer = MinMaxScaler()\n    elif method == 'NONE':\n        return X_train, X_test\n    else:\n        raise Exception(f\"Scale: {method} is not implemented\")\n\n    X_train = transformer.fit_transform(X_train)\n    X_test = transformer.transform(X_test)\n    return X_train, X_test\n\n\ndef impute_mv(X_train: np.array, X_test: np.array, method: str = 'mean'):\n    if method == 'median':\n        imp = SimpleImputer(missing_values=np.nan, strategy='median')\n    elif method == 'mean':\n        imp = SimpleImputer(missing_values=np.nan,strategy='mean')\n    elif method == 'KNN':\n        K=3\n        imp = KNNImputer(n_neighbors=K)\n    elif method == 'iterative': #aka mice\n        imp = IterativeImputer(estimator=BayesianRidge(), n_nearest_features=None, imputation_order='ascending')\n\n    else:\n        raise Exception(f\"Impute: {method} is not implemented\")\n\n    X_train = imp.fit_transform(X_train)\n    X_test = imp.fit_transform(X_test)\n\n    return X_train, X_test\n\n\ndef detect_remove_outliers(X_train: np.array, y_train: np.array, X_test: np.array):\n    # TODO\n    train_pred_indices, test_pred = detect_outlier_obs(X_train, y_train, X_test)\n    #TODO:: UPDATE TO GET THE SPECIFIC INDICES BACK\n    X_train = X_train[train_pred_indices]\n#     X_test = X_test[train_pred]\n    return X_train, X_test\n\n\ndef detect_outlier_obs(X_train: np.array, y_train: np.array, X_test: np.array, method: str = 'coresets'):\n    train_pred, test_pred = [], []\n    if method == 'ECOD':\n        for i in range(X_train.shape[1]):\n            ecod = ECOD(contamination=0.05)\n            ecod.fit(X_train[:, i].reshape(-1, 1))\n            y_train_pred = np.array(ecod.labels_) == 0\n            y_test_pred = np.array(ecod.predict(X_test[:, i].reshape(-1, 1))) == 0\n            train_pred.append(y_train_pred)\n            test_pred.append(y_test_pred)\n\n    elif method == 'isolation_forest':\n        for i in range(X_train.shape[1]):\n            clf = IsolationForest(n_estimators=150, max_samples='auto', contamination=float(0.1))\n            y_train_pred = np.array(clf.fit_predict(X_train[:, i].reshape(-1, 1))) == 1\n            y_test_pred = np.array(clf.predict(X_test[:, i].reshape(-1, 1))) == 1\n            train_pred.append(y_train_pred)\n            test_pred.append(y_test_pred)\n\n#             print(sum([t == -1 for t iisolation_forestn y_test_pred]))\n    elif method==\"coresets\":\n \n        tree = CoresetTreeServiceDTC(optimized_for = 'cleaning')\n        tree = tree.build(X=X_train,y=y_train, chunk_size=-1)\n        result = tree.get_cleaning_samples(20)\n        print(result)\n#         treeCoreset=tree.get_coreset(level=y_train.shape[0])\n        tree.remove_samples(result['idx'])\n#         print(tree.auto_preprocessing())\n#         treeCoreset=tree.get_coreset(level=X_train.shape[0])\n        res = tree.get_cleaning_samples(1212)\n#         indices,xTrain,yTrain=treeCoreset['data']\n        print(res['idx'].shape)\n        train_pred.append(res['idx'])\n#         print(xTrain.shape)\n#         print(yTrain.shape)\n\n    else:\n        raise Exception(f\"Detect: {method} is not implemented\")\n    print(train_pred)\n    return train_pred, test_pred","metadata":{"execution":{"iopub.status.busy":"2023-10-28T18:36:13.364934Z","iopub.execute_input":"2023-10-28T18:36:13.365463Z","iopub.status.idle":"2023-10-28T18:36:13.400949Z","shell.execute_reply.started":"2023-10-28T18:36:13.365424Z","shell.execute_reply":"2023-10-28T18:36:13.399742Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# test\ndef read_data(X_train_path, y_train_path, X_test_path):\n    X_train = np.genfromtxt(X_train_path, delimiter=\",\")\n    y_train = np.genfromtxt(y_train_path, delimiter=\",\")\n    X_test = np.genfromtxt(X_test_path, delimiter=\",\")\n    return X_train, y_train, X_test\n\nxTrainPath=\"/kaggle/input/aml-task1-allfiles/X_train.csv\"\nyTrainPath=\"/kaggle/input/aml-task1-allfiles/y_train.csv\"\nxTestPath=\"/kaggle/input/aml-task1-allfiles/X_test.csv\"\nX_train, y_train, X_test = read_data(X_train_path=xTrainPath,\n                                     y_train_path=yTrainPath,\n                                     X_test_path=xTestPath)\nids_train, ids_test = X_train[1:, 0], X_test[1:, 0].astype(int)\nX_train, y_train, X_test = X_train[1:, 1:], y_train[1:, 1:].ravel(), X_test[1:, 1:]\nX_train, y_train, X_test = preprocess(X_train, y_train, X_test)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-28T18:36:19.259496Z","iopub.execute_input":"2023-10-28T18:36:19.260007Z","iopub.status.idle":"2023-10-28T18:36:23.423546Z","shell.execute_reply.started":"2023-10-28T18:36:19.259968Z","shell.execute_reply":"2023-10-28T18:36:23.421766Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Done with imputation\nDone with Scaling\n{'idx': array([ 514,  972,  219,  661,  396,  740,  257,  189,  304,  295,  967,\n        973,  593,  492,  868,  522, 1152, 1098,  203,  167]), 'X': array([[0.53635734, 0.29711162, 0.45551874, ..., 0.51369909, 0.31247425,\n        0.50399746],\n       [0.42336666, 0.53088952, 0.62083674, ..., 0.64987716, 0.45522162,\n        0.44872309],\n       [0.41517125, 0.39780631, 0.33961371, ..., 0.36922128, 0.80351068,\n        0.49648618],\n       ...,\n       [0.45500437, 0.37986422, 0.47377481, ..., 0.35594187, 0.16130835,\n        0.46243459],\n       [0.24742966, 0.31121444, 0.40946946, ..., 0.29630813, 0.5377157 ,\n        0.51048071],\n       [0.1839957 , 0.01986472, 0.        , ..., 0.13870795, 0.45843811,\n        0.54971493]]), 'y': array([69., 65., 79., 78., 60., 60., 83., 58., 87., 52., 88., 49., 50.,\n       48., 48., 45., 93., 94., 47., 44.]), 'importance': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n       0.98387393, 1.        , 1.        , 1.        , 1.        ,\n       1.        , 1.        , 1.        , 1.        , 0.98100054,\n       1.        , 1.        , 1.        , 1.        , 1.        ])}\n(1192,)\n[array([ 658,  345,  158, ...,  856,   27, 1196])]\nDone with outliers\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[48], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m ids_train, ids_test \u001b[38;5;241m=\u001b[39m X_train[\u001b[38;5;241m1\u001b[39m:, \u001b[38;5;241m0\u001b[39m], X_test[\u001b[38;5;241m1\u001b[39m:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     15\u001b[0m X_train, y_train, X_test \u001b[38;5;241m=\u001b[39m X_train[\u001b[38;5;241m1\u001b[39m:, \u001b[38;5;241m1\u001b[39m:], y_train[\u001b[38;5;241m1\u001b[39m:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mravel(), X_test[\u001b[38;5;241m1\u001b[39m:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m---> 16\u001b[0m X_train, y_train, X_test \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[47], line 14\u001b[0m, in \u001b[0;36mpreprocess\u001b[0;34m(X_train, y_train, X_test)\u001b[0m\n\u001b[1;32m     11\u001b[0m     X_train, X_test \u001b[38;5;241m=\u001b[39m detect_remove_outliers(X_train,y_train, X_test)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone with outliers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m     X_train, X_test \u001b[38;5;241m=\u001b[39m \u001b[43mselect_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone with Feature selection\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#     X_train, X_test = reduce_dim(X_train, X_test)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#     print(\"Done with reducing dim\")\u001b[39;00m\n","Cell \u001b[0;32mIn[47], line 39\u001b[0m, in \u001b[0;36mselect_features\u001b[0;34m(X_train, y_train, X_test)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect_features\u001b[39m(X_train: np\u001b[38;5;241m.\u001b[39marray, y_train: np\u001b[38;5;241m.\u001b[39marray, X_test: np\u001b[38;5;241m.\u001b[39marray):\n\u001b[0;32m---> 39\u001b[0m     X_train, X_test \u001b[38;5;241m=\u001b[39m \u001b[43mremove_correlated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# # Chi\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# f_p_values = chi2(X_train, y_train)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# print(f_p_values)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# Select k best\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     fs \u001b[38;5;241m=\u001b[39m SelectKBest(score_func\u001b[38;5;241m=\u001b[39mf_regression, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m175\u001b[39m)\n","Cell \u001b[0;32mIn[47], line 56\u001b[0m, in \u001b[0;36mremove_correlated\u001b[0;34m(X_train, X_test)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_correlated\u001b[39m(X_train: np\u001b[38;5;241m.\u001b[39marray, X_test: np\u001b[38;5;241m.\u001b[39marray):\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# Constant features\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     var_threshold \u001b[38;5;241m=\u001b[39m VarianceThreshold(threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# threshold = 0 for constant\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     \u001b[43mvar_threshold\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     var_threshold\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# Correlated\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    877\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/feature_selection/_variance_threshold.py:98\u001b[0m, in \u001b[0;36mVarianceThreshold.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Learn empirical variances from X.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    Returns the instance itself.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m---> 98\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# sparse matrix\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     _, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariances_ \u001b[38;5;241m=\u001b[39m mean_variance_axis(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 565\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    912\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    913\u001b[0m     )\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 915\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m     )\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m    921\u001b[0m     _assert_all_finite(\n\u001b[1;32m    922\u001b[0m         array,\n\u001b[1;32m    923\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    924\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    925\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    926\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: Found array with dim 3. VarianceThreshold expected <= 2."],"ename":"ValueError","evalue":"Found array with dim 3. VarianceThreshold expected <= 2.","output_type":"error"}]},{"cell_type":"code","source":"###################### Train ######################\n# import numpy as np\n# from sklearn.ensemble import ExtraTreesRegressor, AdaBoostRegressor, StackingRegressor, RandomForestRegressor\n# from sklearn.kernel_ridge import KernelRidge\n# from sklearn.linear_model import RidgeCV, Lasso, ElasticNet, LinearRegression\n# from sklearn.model_selection import KFold\n# from sklearn.neighbors import KNeighborsRegressor\n# from sklearn.svm import LinearSVR, SVR\n# from xgboost import XGBRegressor\n# from preprocess import preprocess\n# from sklearn.metrics import r2_score\n\nnp.random.seed(42)\n\n\ndef read_data(X_train_path, y_train_path, X_test_path):\n    X_train = np.genfromtxt(X_train_path, delimiter=\",\")\n    y_train = np.genfromtxt(y_train_path, delimiter=\",\")\n    X_test = np.genfromtxt(X_test_path, delimiter=\",\")\n    return X_train, y_train, X_test\n\n\ndef get_model():\n    estimators = [\n        ('lr', RidgeCV()),\n        ('lasso', Lasso(alpha=0.134694)),\n        # ('enet', ElasticNet(alpha=0.201, l1_ratio=0.005)),\n        # ('lm', LinearRegression()),\n        # ('kernel_ridge', KernelRidge(alpha=2.0, kernel='polynomial', degree=1, coef0=0.005)),\n        ('xgb', XGBRegressor(n_estimators=1000, max_depth=7, eta=0.1, colsample_bytree=0.8)),\n        ('extratree', ExtraTreesRegressor(n_estimators=1000, random_state=0)),\n        ('adaboost', AdaBoostRegressor(n_estimators=1000, random_state=0)),\n        # ('svr_lin', SVR(kernel='linear')),\n        # ['svr_rbf', SVR(kernel='rbf')],\n        ('mn', KNeighborsRegressor()),\n    ]\n    model = StackingRegressor(estimators=estimators,\n                           final_estimator=RandomForestRegressor(n_estimators=100, random_state=42))\n    return model\n\n\ndef get_splits(X_train: np.array, nfolds: int = 10):\n    kf = KFold(n_splits=nfolds, random_state=42, shuffle=True)\n    return kf.split(X_train)\n\n\ndef main():\n    methods={\n        \"impute_data\": ['median','mean','iterative','KNN'],\n        \"outlier_detection\":['ECOD','isolation_forest'],\n        \"feature_selection\":[],\n        \"scale_data\":[\"NONE\"],\n        \"reduce_dim\":[\"NONE\"]\n    }\n    xTrainPath=\"/kaggle/input/aml-task1-allfiles/X_train.csv\"\n    yTrainPath=\"/kaggle/input/aml-task1-allfiles/y_train.csv\"\n    xTestPath=\"/kaggle/input/aml-task1-allfiles/X_test.csv\"\n    X_train, y_train, X_test = read_data(X_train_path=xTrainPath,\n                                         y_train_path=yTrainPath,\n                                         X_test_path=xTestPath)\n    ids_train, ids_test = X_train[1:, 0], X_test[1:, 0].astype(int)\n    X_train, y_train, X_test = X_train[1:, 1:], y_train[1:, 1:].ravel(), X_test[1:, 1:]\n    X_train, y_train, X_test = preprocess(X_train, y_train, X_test)\n\n    print(\"Preprocessed.\")\n\n    model = get_model()\n\n    nfolds = 10\n    splits = get_splits(X_train, nfolds)\n\n    print(\"\\nModels and folds.\")\n\n    r2 = 0\n    for i, (train_index, test_index) in enumerate(splits):\n        model.fit(X_train[train_index], y_train[train_index])\n        pred = model.predict(X_train[test_index])\n        score = r2_score(y_train[test_index], pred)\n        r2 += score\n\n        print(f\"Fold {i} R2 score: {score}\")\n\n    print(f\"\\nAvg R2: {r2 / nfolds}\")\n\n    print(\"\\nTrained.\")\n\n    model.fit(X_train, y_train)\n    pred = model.predict(X_test)\n    res = np.column_stack((ids_test, pred))\n    np.savetxt(\"data/out.csv\", res, fmt=['%1i', '%1.4f'], delimiter=\",\", header=\"id,y\", comments='')\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T22:05:28.323849Z","iopub.execute_input":"2023-10-25T22:05:28.324285Z","iopub.status.idle":"2023-10-25T22:15:32.010249Z","shell.execute_reply.started":"2023-10-25T22:05:28.324252Z","shell.execute_reply":"2023-10-25T22:15:32.008763Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Done with imputation\nDone with Scaling\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 87\u001b[0m\n\u001b[1;32m     83\u001b[0m     np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/out.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, res, fmt\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%1i\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%1.4f\u001b[39;00m\u001b[38;5;124m'\u001b[39m], delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid,y\u001b[39m\u001b[38;5;124m\"\u001b[39m, comments\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 87\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[6], line 56\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m ids_train, ids_test \u001b[38;5;241m=\u001b[39m X_train[\u001b[38;5;241m1\u001b[39m:, \u001b[38;5;241m0\u001b[39m], X_test[\u001b[38;5;241m1\u001b[39m:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     55\u001b[0m X_train, y_train, X_test \u001b[38;5;241m=\u001b[39m X_train[\u001b[38;5;241m1\u001b[39m:, \u001b[38;5;241m1\u001b[39m:], y_train[\u001b[38;5;241m1\u001b[39m:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mravel(), X_test[\u001b[38;5;241m1\u001b[39m:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m---> 56\u001b[0m X_train, y_train, X_test \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreprocessed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model()\n","Cell \u001b[0;32mIn[5], line 23\u001b[0m, in \u001b[0;36mpreprocess\u001b[0;34m(X_train, y_train, X_test)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone with Scaling\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# TODO\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m X_train, X_test \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_remove_outliers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone with outliers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m X_train, X_test \u001b[38;5;241m=\u001b[39m select_features(X_train, y_train, X_test)\n","Cell \u001b[0;32mIn[5], line 111\u001b[0m, in \u001b[0;36mdetect_remove_outliers\u001b[0;34m(X_train, X_test)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect_remove_outliers\u001b[39m(X_train: np\u001b[38;5;241m.\u001b[39marray, X_test: np\u001b[38;5;241m.\u001b[39marray):\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m# TODO\u001b[39;00m\n\u001b[1;32m    110\u001b[0m     train_pred, test_pred \u001b[38;5;241m=\u001b[39m detect_outlier_obs(X_train, X_test)\n\u001b[0;32m--> 111\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_pred\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    112\u001b[0m     X_test \u001b[38;5;241m=\u001b[39m X_test[train_pred]\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X_train, X_test\n","\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 1212 but corresponding boolean dimension is 832"],"ename":"IndexError","evalue":"boolean index did not match indexed array along dimension 0; dimension is 1212 but corresponding boolean dimension is 832","output_type":"error"}]}]}